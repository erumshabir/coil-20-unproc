{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UII\n",
      "['.anaconda', '.android', '.AndroidStudio3.5', '.conda', '.condarc', '.gradle', '.ipynb_checkpoints', '.ipython', '.jupyter', '.keras', '.matplotlib', '3- cats_dogs-convnets.ipynb', '3D Objects', 'Anaconda3', 'AndroidStudioProjects', 'AppData', 'Application Data', 'Basic-Quaternary-Multi-Input-Operators-Truth-Table.png', 'coil-20-unproc.ipynb', 'Contacts', 'Cookies', 'Datasets', 'Desktop', 'Documents', 'Downloads', 'DS_3- cats_dogs-convnets.ipynb', 'Favorites', 'IntelGraphicsProfiles', 'Links', 'Local Settings', 'MicrosoftEdgeBackups', 'Music', 'My Documents', 'NetHood', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{fd9a35db-49fe-11e9-aa2c-248a07783950}.TM.blf', 'NTUSER.DAT{fd9a35db-49fe-11e9-aa2c-248a07783950}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{fd9a35db-49fe-11e9-aa2c-248a07783950}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'OneDrive', 'Pictures', 'PrintHood', 'Recent', 'Saved Games', 'Searches', 'SendTo', 'Start Menu', 'Templates', 'Untitled.ipynb', 'Untitled1.ipynb', 'Videos']\n",
      "['obj1__0.png', 'obj1__1.png', 'obj1__10.png', 'obj1__11.png', 'obj1__12.png', 'obj1__13.png', 'obj1__14.png', 'obj1__15.png', 'obj1__16.png', 'obj1__17.png', 'obj1__18.png', 'obj1__19.png', 'obj1__2.png', 'obj1__20.png', 'obj1__21.png', 'obj1__22.png', 'obj1__23.png', 'obj1__24.png', 'obj1__25.png', 'obj1__26.png', 'obj1__27.png', 'obj1__28.png', 'obj1__29.png', 'obj1__3.png', 'obj1__30.png', 'obj1__31.png', 'obj1__32.png', 'obj1__33.png', 'obj1__34.png', 'obj1__35.png', 'obj1__36.png', 'obj1__37.png', 'obj1__38.png', 'obj1__39.png', 'obj1__4.png', 'obj1__40.png', 'obj1__41.png', 'obj1__42.png', 'obj1__43.png', 'obj1__44.png', 'obj1__45.png', 'obj1__46.png', 'obj1__47.png', 'obj1__48.png', 'obj1__49.png', 'obj1__5.png', 'obj1__50.png', 'obj1__51.png', 'obj1__52.png', 'obj1__53.png', 'obj1__54.png', 'obj1__55.png', 'obj1__56.png', 'obj1__57.png', 'obj1__58.png', 'obj1__59.png', 'obj1__6.png', 'obj1__60.png', 'obj1__61.png', 'obj1__62.png', 'obj1__63.png', 'obj1__64.png', 'obj1__65.png', 'obj1__66.png', 'obj1__67.png', 'obj1__68.png', 'obj1__69.png', 'obj1__7.png', 'obj1__70.png', 'obj1__71.png', 'obj1__8.png', 'obj1__9.png', 'obj2__0.png', 'obj2__1.png', 'obj2__10.png', 'obj2__11.png', 'obj2__12.png', 'obj2__13.png', 'obj2__14.png', 'obj2__15.png', 'obj2__16.png', 'obj2__17.png', 'obj2__18.png', 'obj2__19.png', 'obj2__2.png', 'obj2__20.png', 'obj2__21.png', 'obj2__22.png', 'obj2__23.png', 'obj2__24.png', 'obj2__25.png', 'obj2__26.png', 'obj2__27.png', 'obj2__28.png', 'obj2__29.png', 'obj2__3.png', 'obj2__30.png', 'obj2__31.png', 'obj2__32.png', 'obj2__33.png', 'obj2__34.png', 'obj2__35.png', 'obj2__36.png', 'obj2__37.png', 'obj2__38.png', 'obj2__39.png', 'obj2__4.png', 'obj2__40.png', 'obj2__41.png', 'obj2__42.png', 'obj2__43.png', 'obj2__44.png', 'obj2__45.png', 'obj2__46.png', 'obj2__47.png', 'obj2__48.png', 'obj2__49.png', 'obj2__5.png', 'obj2__50.png', 'obj2__51.png', 'obj2__52.png', 'obj2__53.png', 'obj2__54.png', 'obj2__55.png', 'obj2__56.png', 'obj2__57.png', 'obj2__58.png', 'obj2__59.png', 'obj2__6.png', 'obj2__60.png', 'obj2__61.png', 'obj2__62.png', 'obj2__63.png', 'obj2__64.png', 'obj2__65.png', 'obj2__66.png', 'obj2__67.png', 'obj2__68.png', 'obj2__69.png', 'obj2__7.png', 'obj2__70.png', 'obj2__71.png', 'obj2__8.png', 'obj2__9.png', 'obj3__0.png', 'obj3__1.png', 'obj3__10.png', 'obj3__11.png', 'obj3__12.png', 'obj3__13.png', 'obj3__14.png', 'obj3__15.png', 'obj3__16.png', 'obj3__17.png', 'obj3__18.png', 'obj3__19.png', 'obj3__2.png', 'obj3__20.png', 'obj3__21.png', 'obj3__22.png', 'obj3__23.png', 'obj3__24.png', 'obj3__25.png', 'obj3__26.png', 'obj3__27.png', 'obj3__28.png', 'obj3__29.png', 'obj3__3.png', 'obj3__30.png', 'obj3__31.png', 'obj3__32.png', 'obj3__33.png', 'obj3__34.png', 'obj3__35.png', 'obj3__36.png', 'obj3__37.png', 'obj3__38.png', 'obj3__39.png', 'obj3__4.png', 'obj3__40.png', 'obj3__41.png', 'obj3__42.png', 'obj3__43.png', 'obj3__44.png', 'obj3__45.png', 'obj3__46.png', 'obj3__47.png', 'obj3__48.png', 'obj3__49.png', 'obj3__5.png', 'obj3__50.png', 'obj3__51.png', 'obj3__52.png', 'obj3__53.png', 'obj3__54.png', 'obj3__55.png', 'obj3__56.png', 'obj3__57.png', 'obj3__58.png', 'obj3__59.png', 'obj3__6.png', 'obj3__60.png', 'obj3__61.png', 'obj3__62.png', 'obj3__63.png', 'obj3__64.png', 'obj3__65.png', 'obj3__66.png', 'obj3__67.png', 'obj3__68.png', 'obj3__69.png', 'obj3__7.png', 'obj3__70.png', 'obj3__71.png', 'obj3__8.png', 'obj3__9.png', 'obj4__0.png', 'obj4__1.png', 'obj4__10.png', 'obj4__11.png', 'obj4__12.png', 'obj4__13.png', 'obj4__14.png', 'obj4__15.png', 'obj4__16.png', 'obj4__17.png', 'obj4__18.png', 'obj4__19.png', 'obj4__2.png', 'obj4__20.png', 'obj4__21.png', 'obj4__22.png', 'obj4__23.png', 'obj4__24.png', 'obj4__25.png', 'obj4__26.png', 'obj4__27.png', 'obj4__28.png', 'obj4__29.png', 'obj4__3.png', 'obj4__30.png', 'obj4__31.png', 'obj4__32.png', 'obj4__33.png', 'obj4__34.png', 'obj4__35.png', 'obj4__36.png', 'obj4__37.png', 'obj4__38.png', 'obj4__39.png', 'obj4__4.png', 'obj4__40.png', 'obj4__41.png', 'obj4__42.png', 'obj4__43.png', 'obj4__44.png', 'obj4__45.png', 'obj4__46.png', 'obj4__47.png', 'obj4__48.png', 'obj4__49.png', 'obj4__5.png', 'obj4__50.png', 'obj4__51.png', 'obj4__52.png', 'obj4__53.png', 'obj4__54.png', 'obj4__55.png', 'obj4__56.png', 'obj4__57.png', 'obj4__58.png', 'obj4__59.png', 'obj4__6.png', 'obj4__60.png', 'obj4__61.png', 'obj4__62.png', 'obj4__63.png', 'obj4__64.png', 'obj4__65.png', 'obj4__66.png', 'obj4__67.png', 'obj4__68.png', 'obj4__69.png', 'obj4__7.png', 'obj4__70.png', 'obj4__71.png', 'obj4__8.png', 'obj4__9.png', 'obj5__0.png', 'obj5__1.png', 'obj5__10.png', 'obj5__11.png', 'obj5__12.png', 'obj5__13.png', 'obj5__14.png', 'obj5__15.png', 'obj5__16.png', 'obj5__17.png', 'obj5__18.png', 'obj5__19.png', 'obj5__2.png', 'obj5__20.png', 'obj5__21.png', 'obj5__22.png', 'obj5__23.png', 'obj5__24.png', 'obj5__25.png', 'obj5__26.png', 'obj5__27.png', 'obj5__28.png', 'obj5__29.png', 'obj5__3.png', 'obj5__30.png', 'obj5__31.png', 'obj5__32.png', 'obj5__33.png', 'obj5__34.png', 'obj5__35.png', 'obj5__36.png', 'obj5__37.png', 'obj5__38.png', 'obj5__39.png', 'obj5__4.png', 'obj5__40.png', 'obj5__41.png', 'obj5__42.png', 'obj5__43.png', 'obj5__44.png', 'obj5__45.png', 'obj5__46.png', 'obj5__47.png', 'obj5__48.png', 'obj5__49.png', 'obj5__5.png', 'obj5__50.png', 'obj5__51.png', 'obj5__52.png', 'obj5__53.png', 'obj5__54.png', 'obj5__55.png', 'obj5__56.png', 'obj5__57.png', 'obj5__58.png', 'obj5__59.png', 'obj5__6.png', 'obj5__60.png', 'obj5__61.png', 'obj5__62.png', 'obj5__63.png', 'obj5__64.png', 'obj5__65.png', 'obj5__66.png', 'obj5__67.png', 'obj5__68.png', 'obj5__69.png', 'obj5__7.png', 'obj5__70.png', 'obj5__71.png', 'obj5__8.png', 'obj5__9.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "print(os.listdir())\n",
    "\n",
    "path = '.\\\\Datasets\\\\coil-20-unproc'\n",
    "\n",
    "print(os.listdir(path))\n",
    "#C:\\Users\\UII\\Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "original_dataset_dir = '.\\\\Datasets\\\\coil-20-unproc'\n",
    "\n",
    "base_dir = '.\\\\Datasets\\\\coil-20-unproc\\\\prepared'\n",
    "\n",
    "if (not(os.path.exists(base_dir))):\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# Directory with our training obj1 pictures\n",
    "train_obj1_dir = os.path.join(train_dir, 'obj1')\n",
    "os.mkdir(train_obj1_dir)\n",
    "\n",
    "# Directory with our training obj2 pictures\n",
    "train_obj2_dir = os.path.join(train_dir, 'obj2')\n",
    "os.mkdir(train_obj2_dir)\n",
    "\n",
    "# Directory with our training obj3 pictures\n",
    "train_obj3_dir = os.path.join(train_dir, 'obj3')\n",
    "os.mkdir(train_obj3_dir)\n",
    "\n",
    "# Directory with our training obj4 pictures\n",
    "train_obj4_dir = os.path.join(train_dir, 'obj4')\n",
    "os.mkdir(train_obj4_dir)\n",
    "\n",
    "# Directory with our training obj5 pictures\n",
    "train_obj5_dir = os.path.join(train_dir, 'obj5')\n",
    "os.mkdir(train_obj5_dir)\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_obj1_dir = os.path.join(validation_dir, 'obj1')\n",
    "os.mkdir(validation_obj1_dir)\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_obj2_dir = os.path.join(validation_dir, 'obj2')\n",
    "os.mkdir(validation_obj2_dir)\n",
    "\n",
    "validation_obj3_dir = os.path.join(validation_dir, 'obj3')\n",
    "os.mkdir(validation_obj3_dir)\n",
    "\n",
    "validation_obj4_dir = os.path.join(validation_dir, 'obj4')\n",
    "os.mkdir(validation_obj4_dir)\n",
    "\n",
    "validation_obj5_dir = os.path.join(validation_dir, 'obj5')\n",
    "os.mkdir(validation_obj5_dir)\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "test_obj1_dir = os.path.join(test_dir, 'obj1')\n",
    "os.mkdir(test_obj1_dir)\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "test_obj2_dir = os.path.join(test_dir, 'obj2')\n",
    "os.mkdir(test_obj2_dir)\n",
    "\n",
    "test_obj3_dir = os.path.join(test_dir, 'obj3')\n",
    "os.mkdir(test_obj3_dir)\n",
    "\n",
    "test_obj4_dir = os.path.join(test_dir, 'obj4')\n",
    "os.mkdir(test_obj4_dir)\n",
    "\n",
    "test_obj5_dir = os.path.join(test_dir, 'obj5')\n",
    "os.mkdir(test_obj5_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\Datasets\\\\coil-20-unproc\\\\prepared\\\\train\\\\obj1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = ['obj1__{}.png'.format(i) for i in range(1000)]\n",
    "train_obj1_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obj1 (Train/Test) Completed.\n",
      "Obj2 (Train/Test) Completed.\n",
      "Obj3 (Train/Test) Completed.\n",
      "Obj4 (Train/Test) Completed.\n",
      "Obj5 (Train/Test) Completed.\n"
     ]
    }
   ],
   "source": [
    "# Copy 180 obj1 images to train_obj1_dir\n",
    "fnames = ['obj1__{}.png'.format(i) for i in range(35)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_obj2_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# Copy 90 obj1  images to validation_obj1_dir\n",
    "fnames = ['obj1__{}.png'.format(i) for i in range(35,53)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_obj1_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# Copy 90 obj1 images to test_obj1_dir\n",
    "fnames = ['obj1__{}.png'.format(i) for i in range(53,71)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_obj1_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "print(\"Obj1 (Train/Test) Completed.\")\n",
    "\n",
    "\n",
    "# Copy 180 obj2 images to train_obj2_dir\n",
    "fnames = ['obj2__{}.png'.format(i) for i in range(35)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_obj2_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy 90 obj2 images to validation_obj2_dir\n",
    "fnames = ['obj2__{}.png'.format(i) for i in range(35,53)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_obj2_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy 90 obj2 images to test_ob2_dir\n",
    "fnames = ['obj2__{}.png'.format(i) for i in range(53,71)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_obj2_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "print(\"Obj2 (Train/Test) Completed.\")\n",
    "\n",
    "\n",
    "# Copy 180 obj3 images to train_obj3_dir\n",
    "fnames = ['obj3__{}.png'.format(i) for i in range(35)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_obj3_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy 90 obj3 images to validation_obj3_dir\n",
    "fnames = ['obj3__{}.png'.format(i) for i in range(35,53)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_obj3_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy 90 obj3 images to test_obj3_dir\n",
    "fnames = ['obj3__{}.png'.format(i) for i in range(53,71)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_obj3_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "print(\"Obj3 (Train/Test) Completed.\")\n",
    "\n",
    "\n",
    "# Copy 180 obj4 images to train_obj4_dir\n",
    "fnames = ['obj4__{}.png'.format(i) for i in range(35)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_obj4_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy 90 obj4 images to validation_obj4_dir\n",
    "fnames = ['obj4__{}.png'.format(i) for i in range(35,53)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_obj4_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy 90 obj4 images to test_obj4_dir\n",
    "fnames = ['obj4__{}.png'.format(i) for i in range(53,71)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_obj4_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "print(\"Obj4 (Train/Test) Completed.\")\n",
    "\n",
    "# Copy 180 obj5 images to train_obj5_dir\n",
    "fnames = ['obj5__{}.png'.format(i) for i in range(35)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_obj5_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy 90 obj5 images to validation_obj5_dir\n",
    "fnames = ['obj5__{}.png'.format(i) for i in range(35,53)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_obj5_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy 90 obj5 images to test_obj5_dir\n",
    "fnames = ['obj5__{}.png'.format(i) for i in range(53,71)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_obj5_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "print(\"Obj5 (Train/Test) Completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, let's count how many pictures we have in each training split (train/validation/test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training obj1 images: 0\n"
     ]
    }
   ],
   "source": [
    "print('total training obj1 images:', len(os.listdir(train_obj1_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training obj2 images: 70\n"
     ]
    }
   ],
   "source": [
    "print('total training obj2 images:', len(os.listdir(train_obj2_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training obj3 images: 35\n"
     ]
    }
   ],
   "source": [
    "print('total training obj3 images:', len(os.listdir(train_obj3_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training obj4 images: 35\n"
     ]
    }
   ],
   "source": [
    "print('total training obj4 images:', len(os.listdir(train_obj4_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training obj5 images: 35\n"
     ]
    }
   ],
   "source": [
    "print('total training obj5 images:', len(os.listdir(train_obj5_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total validation obj1 images: 18\n"
     ]
    }
   ],
   "source": [
    "print('total validation obj1 images:', len(os.listdir(validation_obj1_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total validation obj2 images: 18\n"
     ]
    }
   ],
   "source": [
    "print('total validation obj2 images:', len(os.listdir(validation_obj2_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total validation obj3 images: 18\n"
     ]
    }
   ],
   "source": [
    "print('total validation obj3 images:', len(os.listdir(validation_obj3_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total validation obj4 images: 18\n"
     ]
    }
   ],
   "source": [
    "print('total validation obj4 images:', len(os.listdir(validation_obj4_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total validation obj5 images: 18\n"
     ]
    }
   ],
   "source": [
    "print('total validation obj5 images:', len(os.listdir(validation_obj5_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total test obj1 images: 18\n"
     ]
    }
   ],
   "source": [
    "print('total test obj1 images:', len(os.listdir(test_obj1_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total test obj2 images: 18\n"
     ]
    }
   ],
   "source": [
    "print('total test obj2 images:', len(os.listdir(test_obj2_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total test obj3 images: 18\n"
     ]
    }
   ],
   "source": [
    "print('total test obj3 images:', len(os.listdir(test_obj3_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total test obj4 images: 18\n"
     ]
    }
   ],
   "source": [
    "print('total test obj4 images:', len(os.listdir(test_obj4_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total test obj5 images: 18\n"
     ]
    }
   ],
   "source": [
    "print('total test obj5 images:', len(os.listdir(test_obj5_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So we have indeed 2000 training images, and then 1000 validation images and 1000 test images. In each split, there is the same number of \n",
    "samples from each class: this is a balanced binary classification problem, which means that classification accuracy will be an appropriate \n",
    "measure of success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our network\n",
    "\n",
    "We've already built a small convnet for MNIST in the previous example, so you should be familiar with them. We will reuse the same \n",
    "general structure: our convnet will be a stack of alternated `Conv2D` (with `relu` activation) and `MaxPooling2D` layers.\n",
    "\n",
    "However, since we are dealing with bigger images and a more complex problem, we will make our network accordingly larger: it will have one \n",
    "more `Conv2D` + `MaxPooling2D` stage. This serves both to augment the capacity of the network, and to further reduce the size of the \n",
    "feature maps, so that they aren't overly large when we reach the `Flatten` layer. Here, since we start from inputs of size 150x150 (a \n",
    "somewhat arbitrary choice), we end up with feature maps of size 7x7 right before the `Flatten` layer.\n",
    "\n",
    "Note that the depth of the feature maps is progressively increasing in the network (from 32 to 128), while the size of the feature maps is \n",
    "decreasing (from 148x148 to 7x7). This is a pattern that you will see in almost all convnets.\n",
    "\n",
    "Since we are attacking a binary classification problem, we are ending the network with a single unit (a `Dense` layer of size 1) and a \n",
    "`sigmoid` activation. This unit will encode the probability that the network is looking at one class or the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\UII\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how the dimensions of the feature maps change with every successive layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our compilation step, we'll go with the `RMSprop` optimizer as usual. Since we ended our network with a single sigmoid unit, we will \n",
    "use binary crossentropy as our loss (as a reminder, check out the table in Chapter 4, section 5 for a cheatsheet on what loss function to \n",
    "use in various situations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "As you already know by now, data should be formatted into appropriately pre-processed floating point tensors before being fed into our \n",
    "network. Currently, our data sits on a drive as JPEG files, so the steps for getting it into our network are roughly:\n",
    "\n",
    "* Read the picture files.\n",
    "* Decode the JPEG content to RBG grids of pixels.\n",
    "* Convert these into floating point tensors.\n",
    "* Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).\n",
    "\n",
    "It may seem a bit daunting, but thankfully Keras has utilities to take care of these steps automatically. Keras has a module with image \n",
    "processing helper tools, located at `keras.preprocessing.image`. In particular, it contains the class `ImageDataGenerator` which allows to \n",
    "quickly set up Python generators that can automatically turn image files on disk into batches of pre-processed tensors. This is what we \n",
    "will use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 175 images belonging to 5 classes.\n",
      "Found 90 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It is good practice to always save your models after training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('coil-20-unproc_small.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the loss and accuracy of the model over the training and validation data during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'ro', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
